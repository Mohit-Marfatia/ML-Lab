{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OzUh4wyJpsjj",
    "outputId": "b07dad6d-17c3-4f2e-d952-415bcd4b942a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-09-09 14:34:39--  https://docs.google.com/spreadsheets/d/1xr7kMY4AJhau6sedvV2X9fbwM4ckWrv-Izoe9LDJxUc/export?format=csv&gid=1812782799\n",
      "Resolving docs.google.com (docs.google.com)... 142.250.183.110, 2404:6800:4009:803::200e\n",
      "Connecting to docs.google.com (docs.google.com)|142.250.183.110|:443... connected.\n",
      "HTTP request sent, awaiting response... 307 Temporary Redirect\n",
      "Location: https://doc-0g-c8-sheets.googleusercontent.com/export/54bogvaave6cua4cdnls17ksc4/lndecgfjl3sasl6bqd4j1ueet0/1725872675000/112261653790527273724/*/1xr7kMY4AJhau6sedvV2X9fbwM4ckWrv-Izoe9LDJxUc?format=csv&gid=1812782799 [following]\n",
      "Warning: wildcards not supported in HTTP.\n",
      "--2024-09-09 14:34:40--  https://doc-0g-c8-sheets.googleusercontent.com/export/54bogvaave6cua4cdnls17ksc4/lndecgfjl3sasl6bqd4j1ueet0/1725872675000/112261653790527273724/*/1xr7kMY4AJhau6sedvV2X9fbwM4ckWrv-Izoe9LDJxUc?format=csv&gid=1812782799\n",
      "Resolving doc-0g-c8-sheets.googleusercontent.com (doc-0g-c8-sheets.googleusercontent.com)... 142.250.70.33, 2404:6800:4009:802::2001\n",
      "Connecting to doc-0g-c8-sheets.googleusercontent.com (doc-0g-c8-sheets.googleusercontent.com)|142.250.70.33|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: unspecified [text/csv]\n",
      "Saving to: ‘datasets/tutorial5_dataset1.csv’\n",
      "\n",
      "datasets/tutorial5_     [  <=>               ] 140.34K   459KB/s    in 0.3s    \n",
      "\n",
      "2024-09-09 14:34:41 (459 KB/s) - ‘datasets/tutorial5_dataset1.csv’ saved [143710]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget -O datasets/tutorial5_dataset1.csv \"https://docs.google.com/spreadsheets/d/1xr7kMY4AJhau6sedvV2X9fbwM4ckWrv-Izoe9LDJxUc/export?format=csv&gid=1812782799\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sa4mTqHUp0cu",
    "outputId": "08960138-d80a-41f0-b3d1-9603d1e221d8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-09-09 14:34:41--  https://docs.google.com/spreadsheets/d/1jXOPv57M_rwr8dgXyd-EZE78-V_MSTXce-J0tSZ9nT4/export?format=csv&gid=28140221\n",
      "Resolving docs.google.com (docs.google.com)... 142.250.183.110, 2404:6800:4009:803::200e\n",
      "Connecting to docs.google.com (docs.google.com)|142.250.183.110|:443... connected.\n",
      "HTTP request sent, awaiting response... 307 Temporary Redirect\n",
      "Location: https://doc-0o-c8-sheets.googleusercontent.com/export/54bogvaave6cua4cdnls17ksc4/i10k1944e7hkkqgfvr3nufjt90/1725872680000/112261653790527273724/*/1jXOPv57M_rwr8dgXyd-EZE78-V_MSTXce-J0tSZ9nT4?format=csv&gid=28140221 [following]\n",
      "Warning: wildcards not supported in HTTP.\n",
      "--2024-09-09 14:34:42--  https://doc-0o-c8-sheets.googleusercontent.com/export/54bogvaave6cua4cdnls17ksc4/i10k1944e7hkkqgfvr3nufjt90/1725872680000/112261653790527273724/*/1jXOPv57M_rwr8dgXyd-EZE78-V_MSTXce-J0tSZ9nT4?format=csv&gid=28140221\n",
      "Resolving doc-0o-c8-sheets.googleusercontent.com (doc-0o-c8-sheets.googleusercontent.com)... 142.250.70.33, 2404:6800:4009:82a::2001\n",
      "Connecting to doc-0o-c8-sheets.googleusercontent.com (doc-0o-c8-sheets.googleusercontent.com)|142.250.70.33|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: unspecified [text/csv]\n",
      "Saving to: ‘datasets/tutorial5_dataset2.csv’\n",
      "\n",
      "datasets/tutorial5_     [  <=>               ] 141.54K   658KB/s    in 0.2s    \n",
      "\n",
      "2024-09-09 14:34:42 (658 KB/s) - ‘datasets/tutorial5_dataset2.csv’ saved [144941]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget -O datasets/tutorial5_dataset2.csv \"https://docs.google.com/spreadsheets/d/1jXOPv57M_rwr8dgXyd-EZE78-V_MSTXce-J0tSZ9nT4/export?format=csv&gid=28140221\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "rjrvO7aSc5FV"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X1    float64\n",
      "X2    float64\n",
      "Y       int64\n",
      "dtype: object\n",
      "X1    float64\n",
      "X2    float64\n",
      "Y       int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file_path = 'datasets/tutorial5_dataset1.csv'\n",
    "dataset1 = pd.read_csv(file_path)\n",
    "\n",
    "file_path2 = 'datasets/tutorial5_dataset2.csv'\n",
    "dataset2 = pd.read_csv(file_path2)\n",
    "\n",
    "\n",
    "print(dataset1.dtypes)\n",
    "print(dataset2.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "1-Wp9cdUpqg4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            X1        X2\n",
      "0     1.384203 -1.117639\n",
      "1     0.971769 -1.040159\n",
      "2     0.572429  0.586741\n",
      "3    -0.637732 -1.010381\n",
      "4    -0.785775 -0.249327\n",
      "...        ...       ...\n",
      "4995  1.114626  0.539304\n",
      "4996 -0.378111  1.002081\n",
      "4997  2.900782  2.447491\n",
      "4998  1.934068  2.563033\n",
      "4999 -0.701798 -0.519068\n",
      "\n",
      "[5000 rows x 2 columns]\n",
      "0       0\n",
      "1       0\n",
      "2       0\n",
      "3       0\n",
      "4       0\n",
      "       ..\n",
      "4995    1\n",
      "4996    1\n",
      "4997    1\n",
      "4998    1\n",
      "4999    0\n",
      "Name: Y, Length: 5000, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Perform basic EDA\n",
    "# dataset1\n",
    "X_d1 = dataset1.drop(['Y'], axis = 1)\n",
    "y_d1 = dataset1['Y']\n",
    "\n",
    "print(X_d1)\n",
    "print(y_d1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            X1        X2\n",
      "0    -0.218879 -1.054567\n",
      "1    -0.151691  0.129630\n",
      "2    -0.741902  0.356992\n",
      "3     0.901059  0.172920\n",
      "4     0.122947  0.540798\n",
      "...        ...       ...\n",
      "4995  0.452376  0.827228\n",
      "4996 -0.159475  0.325517\n",
      "4997  0.829901  1.116723\n",
      "4998  0.630664  0.195359\n",
      "4999  0.235054  0.062855\n",
      "\n",
      "[5000 rows x 2 columns]\n",
      "0       0\n",
      "1       0\n",
      "2       1\n",
      "3       1\n",
      "4       1\n",
      "       ..\n",
      "4995    0\n",
      "4996    0\n",
      "4997    0\n",
      "4998    0\n",
      "4999    0\n",
      "Name: Y, Length: 5000, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# dataset2\n",
    "X_d2 = dataset2.drop(['Y'], axis = 1)\n",
    "y_d2 = dataset2['Y']\n",
    "\n",
    "print(X_d2)\n",
    "print(y_d2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns with NA values:\n",
      "X1: 0\n",
      "X2: 0\n",
      "Y: 0\n"
     ]
    }
   ],
   "source": [
    "# Filling in missing values\n",
    "def count_na_values(df):\n",
    "    na_counts = {col: 0 for col in df.columns}\n",
    "\n",
    "    # Iterate through each row and column\n",
    "    for index, row in df.iterrows():\n",
    "        for col in df.columns:\n",
    "            # Check for NA values\n",
    "            if pd.isna(row[col]):\n",
    "                na_counts[col] += 1\n",
    "\n",
    "    print(\"Columns with NA values:\")\n",
    "    for column, count in na_counts.items():\n",
    "        # if count > 0:\n",
    "        print(f\"{column}: {count}\")\n",
    "        # else: \n",
    "            # print(\"No columns with NA values\")\n",
    "\n",
    "# numerical_columns = df.select_dtypes(include=['float64', 'int64']) \n",
    "count_na_values(dataset1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns with NA values:\n",
      "X1: 0\n",
      "X2: 0\n",
      "Y: 0\n"
     ]
    }
   ],
   "source": [
    "def count_na_values(df):\n",
    "    na_counts = {col: 0 for col in df.columns}\n",
    "\n",
    "    # Iterate through each row and column\n",
    "    for index, row in df.iterrows():\n",
    "        for col in df.columns:\n",
    "            # Check for NA values\n",
    "            if pd.isna(row[col]):\n",
    "                na_counts[col] += 1\n",
    "\n",
    "    print(\"Columns with NA values:\")\n",
    "    for column, count in na_counts.items():\n",
    "        # if count > 0:\n",
    "        print(f\"{column}: {count}\")\n",
    "        # else: \n",
    "            # print(\"No columns with NA values\")\n",
    "count_na_values(dataset2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X1_train, X1_test, y1_train, y1_test = train_test_split(X_d1, y_d1, test_size=0.2, random_state=42, stratify=y_d1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2_train, X2_test, y2_train, y2_test = train_test_split(X_d2, y_d2, test_size=0.2, random_state=42, stratify=y_d2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "R1nfR1-ke8r_"
   },
   "outputs": [],
   "source": [
    "#Implement Logistic Regression on dataset1 and compute its accuracy\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def sigmoid(z):\n",
    "    \"\"\"\n",
    "    Compute the sigmoid function.\n",
    "\n",
    "    Parameters:\n",
    "    z : numpy array\n",
    "        Linear combination of weights and input features.\n",
    "\n",
    "    Returns:\n",
    "    numpy array\n",
    "        Sigmoid of input z.\n",
    "    \"\"\"\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "def initialize_weights(n_features):\n",
    "    \"\"\"\n",
    "    Initialize weights and bias to zero.\n",
    "\n",
    "    Parameters:\n",
    "    n_features : int\n",
    "        Number of features in the dataset.\n",
    "\n",
    "    Returns:\n",
    "    tuple\n",
    "        Initialized weights and bias.\n",
    "    \"\"\"\n",
    "    # initialize the weights and bias to zero (hint: make sure dimentions are correct)\n",
    "    weights = np.zeros(n_features)\n",
    "    bias = 0\n",
    "    return weights, bias\n",
    "\n",
    "def compute_cost(y, y_pred):\n",
    "    \"\"\"\n",
    "    Compute the cost function for logistic regression.\n",
    "\n",
    "    Parameters:\n",
    "    y : numpy array\n",
    "        Actual labels.\n",
    "    y_pred : numpy array\n",
    "        Predicted probabilities.\n",
    "\n",
    "    Returns:\n",
    "    float\n",
    "        The cost value.\n",
    "    \"\"\"\n",
    "    # compute the cost\n",
    "    m = y.shape[0]\n",
    "    cost = - (1/m) * np.sum(y * np.log(y_pred) + (1 - y) * np.log(1 - y_pred))\n",
    "    return cost\n",
    "\n",
    "def compute_gradients(X, y, y_pred):\n",
    "    \"\"\"\n",
    "    Compute the gradients for weights and bias.\n",
    "\n",
    "    Parameters:\n",
    "    X : numpy array\n",
    "        Feature matrix.\n",
    "    y : numpy array\n",
    "        Actual labels.\n",
    "    y_pred : numpy array\n",
    "        Predicted probabilities.\n",
    "\n",
    "    Returns:\n",
    "    tuple\n",
    "        Gradients of weights and bias.\n",
    "    \"\"\"\n",
    "    n = X.shape[0]\n",
    "\n",
    "    # compute dw\n",
    "    dw = (1/n) * np.dot(X.T, (y_pred - y))\n",
    "    # compute db\n",
    "    db = (1/n) * np.sum(y_pred - y)\n",
    "    \n",
    "    return dw, db\n",
    "\n",
    "\n",
    "def optimize(X, y, weights, bias, learning_rate, num_iterations):\n",
    "    \"\"\"\n",
    "    Perform gradient descent to optimize weights and bias.\n",
    "\n",
    "    Parameters:\n",
    "    X : numpy array\n",
    "        Feature matrix.\n",
    "    y : numpy array\n",
    "        Actual labels.\n",
    "    weights : numpy array\n",
    "        Weights of the model.\n",
    "    bias : float\n",
    "        Bias of the model.\n",
    "    learning_rate : float\n",
    "        Learning rate for gradient descent.\n",
    "    num_iterations : int\n",
    "        Number of iterations for gradient descent.\n",
    "\n",
    "    Returns:\n",
    "    tuple\n",
    "        Optimized weights, bias, and the list of costs.\n",
    "    \"\"\"\n",
    "    costs = []\n",
    "\n",
    "    for i in range(num_iterations):\n",
    "        # Compute linear model\n",
    "        z = np.dot(X, weights) + bias\n",
    "        # Apply sigmoid function\n",
    "        y_pred = sigmoid(z)\n",
    "        # Compute cost\n",
    "        cost = compute_cost(y, y_pred)\n",
    "        costs.append(cost)\n",
    "        # Compute gradients\n",
    "        dw, db = compute_gradients(X, y, y_pred)\n",
    "        # Update weights and bias\n",
    "        weights = weights - learning_rate * dw\n",
    "        bias = bias - learning_rate * db\n",
    "        # pass\n",
    "    return weights, bias, costs\n",
    "\n",
    "def predict(X, weights, bias):\n",
    "    \"\"\"\n",
    "    Predict the binary labels for a dataset.\n",
    "\n",
    "    Parameters:\n",
    "    X : numpy array\n",
    "        Feature matrix.\n",
    "    weights : numpy array\n",
    "        Weights of the model.\n",
    "    bias : float\n",
    "        Bias of the model.\n",
    "\n",
    "    Returns:\n",
    "    numpy array\n",
    "        Predicted binary labels (0 or 1).\n",
    "    \"\"\"\n",
    "    z = np.dot(X, weights) + bias\n",
    "    y_pred = sigmoid(z)\n",
    "    predictions = [1 if i > 0.5 else 0 for i in y_pred]\n",
    "    return np.array(predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.766\n"
     ]
    }
   ],
   "source": [
    "weights, bias = initialize_weights(X1_train.shape[1])\n",
    "weights, bias, costs = optimize(X1_train, y1_train, weights, bias, 0.01, 10000)\n",
    "y1_pred = predict(X1_test,weights,bias)\n",
    "matches = np.sum(y1_test == y1_pred)\n",
    "mismatches = np.sum(y1_test != y1_pred)\n",
    "print(f\"Accuracy of Logistic Regression for dataset 1: {matches/(matches+mismatches)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "yZIdsaT3fSSw"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Naive Bayes on Dataset 1: 0.762\n"
     ]
    }
   ],
   "source": [
    "def separate_by_class(X, y):\n",
    "    separated = {}\n",
    "    for i in range(len(y)):\n",
    "        class_value = y[i]\n",
    "        if class_value not in separated:\n",
    "            separated[class_value] = []\n",
    "        separated[class_value].append(X[i])\n",
    "    return separated\n",
    "\n",
    "def calculate_mean_variance(dataset):\n",
    "    return [(np.mean(feature), np.var(feature)) for feature in zip(*dataset)]\n",
    "\n",
    "def calculate_gaussian_probability(x, mean, variance):\n",
    "    exponent = np.exp(-((x - mean)**2 / (2 * variance)))\n",
    "    return (1 / np.sqrt(2 * np.pi * variance)) * exponent\n",
    "\n",
    "def calculate_class_probabilities(summaries, input_data):\n",
    "    probabilities = {}\n",
    "    for class_value, class_summaries in summaries.items():\n",
    "        probabilities[class_value] = 1\n",
    "        for i in range(len(class_summaries)):\n",
    "            mean, variance = class_summaries[i]\n",
    "            probabilities[class_value] *= calculate_gaussian_probability(input_data[i], mean, variance)\n",
    "    return probabilities\n",
    "\n",
    "def predict_naive(summaries, input_data):\n",
    "    probabilities = calculate_class_probabilities(summaries, input_data)\n",
    "    return max(probabilities, key=probabilities.get)\n",
    "\n",
    "def summarize_by_class(X, y):\n",
    "    separated = separate_by_class(X, y)\n",
    "    summaries = {}\n",
    "    for class_value, instances in separated.items():\n",
    "        summaries[class_value] = calculate_mean_variance(instances)\n",
    "    return summaries\n",
    "\n",
    "def naive_bayes(X_train, y_train, X_test):\n",
    "    summaries = summarize_by_class(X_train, y_train)\n",
    "    predictions = [predict_naive(summaries, x) for x in X_test]\n",
    "    return np.array(predictions)\n",
    "\n",
    "def compute_accuracy(y_true, y_pred):\n",
    "    return np.mean(y_true == y_pred)\n",
    "\n",
    "X = dataset1[['X1', 'X2']].values\n",
    "y = dataset1['Y'].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "y_pred = naive_bayes(X_train, y_train, X_test)\n",
    "accuracy = compute_accuracy(y_test, y_pred)\n",
    "print(\"Accuracy of Naive Bayes on Dataset 1:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "hc4Wd-QVfT6T"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Logistic Regression for dataset 2: 0.711\n",
      "Accuracy of Naive Bayes on Dataset 2: 0.7\n"
     ]
    }
   ],
   "source": [
    "#Implement Naive Bayes on dataset2 and compute its accuracy\n",
    "weights, bias = initialize_weights(X2_train.shape[1])\n",
    "weights, bias, costs = optimize(X2_train, y2_train, weights, bias, 0.01, 10000)\n",
    "y2_pred = predict(X2_test,weights,bias)\n",
    "matches = np.sum(y2_test == y2_pred)\n",
    "mismatches = np.sum(y2_test != y2_pred)\n",
    "print(f\"Accuracy of Logistic Regression for dataset 2: {matches/(matches+mismatches)}\")\n",
    "\n",
    "X = dataset2[['X1', 'X2']].values\n",
    "y = dataset2['Y'].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "y_pred = naive_bayes(X_train, y_train, X_test)\n",
    "accuracy = compute_accuracy(y_test, y_pred)\n",
    "print(\"Accuracy of Naive Bayes on Dataset 2:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hyqB40-cj9vk"
   },
   "source": [
    "#Based on the results, explain which model works better on each dataset and why."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "w-sykMQmoiNx"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for col in dataset1.columns[:-1]:\n",
    "    if dataset1[col].dtype == 'object':\n",
    "        count += 1\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X1\n",
      "X2\n"
     ]
    }
   ],
   "source": [
    "for x in X1_train:\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
