


!wget -O datasets/tutorial4.csv "https://docs.google.com/spreadsheets/d/1RNtDIvisrnOmjJxS7aPm-45NtOH3qd5-mgd2bHeSOGA/export?format=csv&gid=1727131321"
import pandas as pd
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split

df=pd.read_csv('datasets/tutorial4.csv')

df.head()
X = df.drop(['RainTomorrow'], axis=1)
y = df['RainTomorrow']
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)
X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42, stratify=y)






X_train


import numpy as np

def sigmoid(z):
    """
    Compute the sigmoid function.

    Parameters:
    z : numpy array
        Linear combination of weights and input features.

    Returns:
    numpy array
        Sigmoid of input z.
    """
    return 1 / (1 + np.exp(-z))

def initialize_weights(n_features):
    """
    Initialize weights and bias to zero.

    Parameters:
    n_features : int
        Number of features in the dataset.

    Returns:
    tuple
        Initialized weights and bias.
    """
    # initialize the weights and bias to zero (hint: make sure dimentions are correct)
    weights = np.zeros(n_features)
    bias = 0
    return weights, bias

def compute_cost(y, y_pred):
    """
    Compute the cost function for logistic regression.

    Parameters:
    y : numpy array
        Actual labels.
    y_pred : numpy array
        Predicted probabilities.

    Returns:
    float
        The cost value.
    """
    # compute the cost
    m = y.shape[0]
    cost = - (1/m) * np.sum(y * np.log(y_pred) + (1 - y) * np.log(1 - y_pred))
    return cost

def compute_gradients(X, y, y_pred):
    """
    Compute the gradients for weights and bias.

    Parameters:
    X : numpy array
        Feature matrix.
    y : numpy array
        Actual labels.
    y_pred : numpy array
        Predicted probabilities.

    Returns:
    tuple
        Gradients of weights and bias.
    """
    n = X.shape[0]

    # compute dw
    dw = (1/n) * np.dot(X.T, (y_pred - y))
    # compute db
    db = (1/n) * np.sum(y_pred - y)
    
    return dw, db


def optimize(X, y, weights, bias, learning_rate, num_iterations):
    """
    Perform gradient descent to optimize weights and bias.

    Parameters:
    X : numpy array
        Feature matrix.
    y : numpy array
        Actual labels.
    weights : numpy array
        Weights of the model.
    bias : float
        Bias of the model.
    learning_rate : float
        Learning rate for gradient descent.
    num_iterations : int
        Number of iterations for gradient descent.

    Returns:
    tuple
        Optimized weights, bias, and the list of costs.
    """
    costs = []

    for i in range(num_iterations):
        # Compute linear model
        z = np.dot(X, weights) + bias
        # Apply sigmoid function
        y_pred = sigmoid(z)
        # Compute cost
        cost = compute_cost(y, y_pred)
        costs.append(cost)
        # Compute gradients
        dw, db = compute_gradients(X, y, y_pred)
        # Update weights and bias
        weights = weights - learning_rate * dw
        bias = bias - learning_rate * db
        # pass
    return weights, bias, costs

def predict(X, weights, bias):
    """
    Predict the binary labels for a dataset.

    Parameters:
    X : numpy array
        Feature matrix.
    weights : numpy array
        Weights of the model.
    bias : float
        Bias of the model.

    Returns:
    numpy array
        Predicted binary labels (0 or 1).
    """
    z = np.dot(X, weights) + bias
    y_pred = sigmoid(z)
    predictions = [1 if i > 0.5 else 0 for i in y_pred]
    return np.array(predictions)






weights, bias = initialize_weights(X_train.shape[1])
weights, bias, costs = optimize(X_train, y_train, weights, bias, 1, 20000)
y_pred = predict(X_test,weights,bias)
matches = np.sum(y_test == y_pred)
mismatches = np.sum(y_test != y_pred)
print(f"Accuracy: {matches/(matches+mismatches)}")






